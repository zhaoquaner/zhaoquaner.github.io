<!DOCTYPE html><html lang="zh-CN" data-default-color-scheme="auto"><head><meta charset="UTF-8"><link rel="apple-touch-icon" sizes="76x76" href="https://crayon-1302863897.cos.ap-beijing.myqcloud.com/blog/blog_images/favicon.png"><link rel="icon" href="https://crayon-1302863897.cos.ap-beijing.myqcloud.com/blog/blog_images/favicon.png"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=5,shrink-to-fit=no"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta name="theme-color" content="#2f4154"><meta name="author" content="ZhaoXin"><meta name="keywords" content="博客"><meta name="description" content="1-线性回归  线性回归概述 回归是能为一个或多个自变量与因变量之间关系建模的一类方法。经常用来表示输入和输出之间的关系。 在机器学习领域中的大多数人物都涉及到预测，当想预测一个数值时，就会涉及到回归问题。  基本元素 线性回归基于几个简单的假设。  自变量x和因变量y之间的关系是线性的，即y可以表示为x元素的加权和，通常允许包含观测值中一些噪声； 假设任何噪声都比较正常，如噪声遵循正态分布；"><meta property="og:type" content="article"><meta property="og:title" content="1-线性回归"><meta property="og:url" content="https://zhaoquaner.github.io/2022/11/21/DeepLearning/practice/1-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/index.html"><meta property="og:site_name" content="赵圈儿的博客"><meta property="og:description" content="1-线性回归  线性回归概述 回归是能为一个或多个自变量与因变量之间关系建模的一类方法。经常用来表示输入和输出之间的关系。 在机器学习领域中的大多数人物都涉及到预测，当想预测一个数值时，就会涉及到回归问题。  基本元素 线性回归基于几个简单的假设。  自变量x和因变量y之间的关系是线性的，即y可以表示为x元素的加权和，通常允许包含观测值中一些噪声； 假设任何噪声都比较正常，如噪声遵循正态分布；"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://crayon-1302863897.cos.ap-beijing.myqcloud.com/image/散点图.svg"><meta property="article:published_time" content="2022-11-21T01:31:57.000Z"><meta property="article:modified_time" content="2022-11-23T09:26:27.686Z"><meta property="article:author" content="ZhaoXin"><meta property="article:tag" content="深度学习实战"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:image" content="https://crayon-1302863897.cos.ap-beijing.myqcloud.com/image/散点图.svg"><title>1-线性回归 - 赵圈儿的博客</title><link rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css"><link rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0/dist/katex.min.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css"><link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css"><link rel="stylesheet" href="/css/main.css"><link id="highlight-css" rel="stylesheet" href="/css/highlight.css"><link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css"><link rel="stylesheet" href="https://crayon-1302863897.cos.ap-beijing.myqcloud.com/blog/css/collpase.css"><link rel="stylesheet" href="https://crayon-1302863897.cos.ap-beijing.myqcloud.com/blog/css/radius.css"><link rel="stylesheet" href="https://crayon-1302863897.cos.ap-beijing.myqcloud.com/blog/css/deletefigcaption.css"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.4/css/all.css"><link rel="stylesheet" href="/css/font.css"><script id="fluid-configs">var Fluid=window.Fluid||{};Fluid.ctx=Object.assign({},Fluid.ctx);var dntVal,CONFIG={hostname:"zhaoquaner.github.io",root:"/",version:"1.8.14",typing:{enable:!0,typeSpeed:30,cursorChar:" ",loop:!1,scope:[]},anchorjs:{enable:!0,element:"h1,h2,h3,h4,h5,h6",placement:"right",visible:"hover",icon:""},progressbar:{enable:!0,height_px:4,color:"#29d",options:{showSpinner:!1,trickleSpeed:100}},code_language:{enable:!0,default:"Text"},copy_btn:!0,image_caption:{enable:!0},image_zoom:{enable:!0,img_url_replace:["",""]},toc:{enable:!0,placement:"left",headingSelector:"h1,h2,h3,h4,h5,h6",collapseDepth:1},lazyload:{enable:!0,loading_img:"/img/loading.gif",onlypost:!1,offset_factor:2},web_analytics:{enable:!0,follow_dnt:!0,baidu:null,google:null,gtag:null,tencent:{sid:null,cid:null},woyaola:null,cnzz:null,leancloud:{app_id:"BzK0JfEpsm40LlV9EPIyl4mp-gzGzoHsz",app_key:"MpxSk6ED55Utq83yNrKAMI5c",server_url:"https://bzk0jfep.lc-cn-n1-shared.com",path:"window.location.pathname",ignore_local:!1}},search_path:"/local-search.xml"};CONFIG.web_analytics.follow_dnt&&(dntVal=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,Fluid.ctx.dnt=dntVal&&(dntVal.startsWith("1")||dntVal.startsWith("yes")||dntVal.startsWith("on")))</script><script src="/js/utils.js"></script><script src="/js/color-schema.js"></script></head><body><style>code{font-weight:400}#board{border-radius:1.5rem}#board-ctn{width:110%;margin-left:-5%}</style><style>.post-content{font-weight:600}</style><header><div class="header-inner" style="height:70vh"><nav id="navbar" class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar"><div class="container"><a class="navbar-brand" href="/"><strong>Personal Blog</strong> </a><button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><div class="animated-icon"><span></span><span></span><span></span></div></button><div class="collapse navbar-collapse" id="navbarSupportedContent"><ul class="navbar-nav ml-auto text-center"><li class="nav-item"><a class="nav-link" href="/"><i class="iconfont icon-home-fill"></i> 首页</a></li><li class="nav-item"><a class="nav-link" href="/archives/"><i class="iconfont icon-archive-fill"></i> 归档</a></li><li class="nav-item"><a class="nav-link" href="/categories/"><i class="iconfont icon-category-fill"></i> 分类</a></li><li class="nav-item"><a class="nav-link" href="/tags/"><i class="iconfont icon-tags-fill"></i> 标签</a></li><li class="nav-item"><a class="nav-link" href="/about/"><i class="iconfont icon-user-fill"></i> 关于</a></li><li class="nav-item"><a class="nav-link" href="javascript:;"><i class="iconfont icon-music"></i> 播放</a></li><li class="nav-item" id="search-btn"><a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">&nbsp;<i class="iconfont icon-search"></i>&nbsp;</a></li><li class="nav-item" id="color-toggle-btn"><a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a></li></ul></div></div></nav><div id="banner" class="banner" parallax="true" style="background:url(https://crayon-1302863897.cos.ap-beijing.myqcloud.com/blog/blog_images/article.png) no-repeat center center;background-size:cover"><div class="full-bg-img"><div class="mask flex-center" style="background-color:rgba(0,0,0,.3)"><div class="banner-text text-center fade-in-up"><div class="h2"><span id="subtitle" data-typed-text="1-线性回归"></span></div><div class="mt-3"><span class="post-meta"><i class="iconfont icon-date-fill" aria-hidden="true"></i> <time datetime="2022-11-21 09:31" pubdate>2022年11月21日</time></span></div><div class="mt-1"><span class="post-meta mr-2"><i class="iconfont icon-chart"></i>10k 字 </span><span id="leancloud-page-views-container" class="post-meta" style="display:none"><i class="iconfont icon-eye" aria-hidden="true"></i> <span id="leancloud-page-views"></span> 次</span></div></div></div></div></div></div></header><main><div class="container-fluid nopadding-x"><div class="row nomargin-x"><div class="side-col d-none d-lg-block col-lg-2"><aside class="sidebar" style="padding-left:2rem;margin-right:-1rem"><div id="toc"><p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p><div class="toc-body" id="toc-body"></div></div></aside></div><div class="col-lg-8 nopadding-x-md"><div class="container nopadding-x-md" id="board-ctn"><div id="board"><article class="post-content mx-auto"><h1 style="display:none">1-线性回归</h1><div class="markdown-body"><h1 id="1-线性回归"><a class="markdownIt-Anchor" href="#1-线性回归"></a> 1-线性回归</h1><h2 id="线性回归概述"><a class="markdownIt-Anchor" href="#线性回归概述"></a> 线性回归概述</h2><p>回归是能为一个或多个自变量与因变量之间关系建模的一类方法。经常用来表示输入和输出之间的关系。</p><p>在机器学习领域中的大多数人物都涉及到预测，当想预测一个数值时，就会涉及到回归问题。</p><h2 id="基本元素"><a class="markdownIt-Anchor" href="#基本元素"></a> 基本元素</h2><p>线性回归基于几个简单的假设。</p><ul><li>自变量x和因变量y之间的关系是线性的，即y可以表示为x元素的加权和，通常允许包含观测值中一些噪声；</li><li>假设任何噪声都比较正常，如噪声遵循正态分布；</li></ul><p>举一个具体的例子：根据房屋面积和房龄来估算房屋价格，需要有一个真实的数据集，数据集中包含了房屋销售价格、面积和房龄。在机器学习术语中，每行数据称为样本(sample)，也可以称为数据点(data point)或数据样本(data instance)。把预测的目标称为标签(label)或目标(target)。预测所依据的自变量称为特征(feature)或协变量(convariate)。</p><p>通常用n表示样本数量，对索引为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.65952em;vertical-align:0"></span><span class="mord mathnormal">i</span></span></span></span>的样本，输入表示为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>x</mi><mi>i</mi></msup><mo>=</mo><mo stretchy="false">[</mo><msubsup><mi>x</mi><mn>1</mn><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msubsup><mo separator="true">,</mo><msubsup><mi>x</mi><mn>2</mn><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msubsup><msup><mo stretchy="false">]</mo><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">x^{i} = [x_1^{(i)}, x_2^{(i)}]^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.824664em;vertical-align:0"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.824664em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.311108em;vertical-align:-.26630799999999993em"></span><span class="mopen">[</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em"><span style="top:-2.433692em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span><span style="top:-3.2198em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">i</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.26630799999999993em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em"><span style="top:-2.433692em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span><span style="top:-3.2198em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">i</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.26630799999999993em"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">]</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8413309999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.13889em">T</span></span></span></span></span></span></span></span></span></span></span>，表示包含两个自变量或特征，对应的标签为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>y</mi><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msup></mrow><annotation encoding="application/x-tex">y^{(i)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0824399999999998em;vertical-align:-.19444em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8879999999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span>。</p><h2 id="线性模型"><a class="markdownIt-Anchor" href="#线性模型"></a> 线性模型</h2><p>线性假设是指目标可以表示为特征的加权和。</p><p>例如：</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>p</mi><mi>r</mi><mi>i</mi><mi>c</mi><mi>e</mi><mo>=</mo><msub><mi>w</mi><mrow><mi>a</mi><mi>r</mi><mi>e</mi><mi>a</mi></mrow></msub><mo>∗</mo><mi>a</mi><mi>r</mi><mi>e</mi><mi>a</mi><mo>+</mo><msub><mi>w</mi><mrow><mi>a</mi><mi>g</mi><mi>e</mi></mrow></msub><mo>∗</mo><mi>a</mi><mi>g</mi><mi>e</mi><mo>+</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">price = w_{area}*area + w_{age} * age +b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.85396em;vertical-align:-.19444em"></span><span class="mord mathnormal">p</span><span class="mord mathnormal" style="margin-right:.02778em">r</span><span class="mord mathnormal">i</span><span class="mord mathnormal">c</span><span class="mord mathnormal">e</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.61528em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.151392em"><span style="top:-2.5500000000000003em;margin-left:-.02691em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:.02778em">r</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">a</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.66666em;vertical-align:-.08333em"></span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:.02778em">r</span><span class="mord mathnormal">e</span><span class="mord mathnormal">a</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.751388em;vertical-align:-.286108em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.15139200000000003em"><span style="top:-2.5500000000000003em;margin-left:-.02691em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:.03588em">g</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.7777700000000001em;vertical-align:-.19444em"></span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:.03588em">g</span><span class="mord mathnormal">e</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord mathnormal">b</span></span></span></span></span></p><p>其中<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mrow><mi>a</mi><mi>r</mi><mi>e</mi><mi>a</mi></mrow></msub></mrow><annotation encoding="application/x-tex">w_{area}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.58056em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.151392em"><span style="top:-2.5500000000000003em;margin-left:-.02691em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:.02778em">r</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">a</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mrow><mi>a</mi><mi>g</mi><mi>e</mi></mrow></msub></mrow><annotation encoding="application/x-tex">w_{age}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.716668em;vertical-align:-.286108em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.15139200000000003em"><span style="top:-2.5500000000000003em;margin-left:-.02691em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:.03588em">g</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span></span></span></span>称为权重(weight)，决定了每个特征对预测值有多大的影响，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord mathnormal">b</span></span></span></span>称为偏置(bias)。偏执是指当所有特征都取值为0时，预测值应该为多少。</p><p>在机器学习领域，通常使用的是高维数据集，建模时使用线性代数表示会更方便。当输入包含d个特征时，预测结果<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>y</mi><mo stretchy="true">^</mo></mover></mrow><annotation encoding="application/x-tex">\widehat{y}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.865em;vertical-align:-.19444em"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.67056em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">y</span></span></span><span class="svg-align" style="width:calc(100% - .11112em);margin-left:.11112em;top:-3.43056em"><span class="pstrut" style="height:3em"></span><span style="height:.24em"><svg width="100%" height="0.24em" viewBox="0 0 1062 239" preserveAspectRatio="none"><path d="M529 0h5l519 115c5 1 9 5 9 10 0 1-1 2-1 3l-4 22
c-1 5-5 9-11 9h-2L532 67 19 159h-2c-5 0-9-4-11-9l-5-22c-1-6 2-12 8-13z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.19444em"><span></span></span></span></span></span></span></span></span>表示为：</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mover accent="true"><mi>y</mi><mo stretchy="true">^</mo></mover><mo>=</mo><msub><mi>w</mi><mn>1</mn></msub><msub><mi>x</mi><mn>1</mn></msub><mo>+</mo><mo>⋯</mo><mo>+</mo><msub><mi>w</mi><mi>d</mi></msub><msub><mi>x</mi><mi>d</mi></msub><mo>+</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">\widehat{y} = w_1x_1 + \cdots + w_dx_d + b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.865em;vertical-align:-.19444em"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.67056em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">y</span></span></span><span class="svg-align" style="width:calc(100% - .11112em);margin-left:.11112em;top:-3.43056em"><span class="pstrut" style="height:3em"></span><span style="height:.24em"><svg width="100%" height="0.24em" viewBox="0 0 1062 239" preserveAspectRatio="none"><path d="M529 0h5l519 115c5 1 9 5 9 10 0 1-1 2-1 3l-4 22
c-1 5-5 9-11 9h-2L532 67 19 159h-2c-5 0-9-4-11-9l-5-22c-1-6 2-12 8-13z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.19444em"><span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.73333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.02691em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.66666em;vertical-align:-.08333em"></span><span class="minner">⋯</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.73333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.33610799999999996em"><span style="top:-2.5500000000000003em;margin-left:-.02691em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.33610799999999996em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">d</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord mathnormal">b</span></span></span></span></span></p><p>将所有特征放到向量<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold-italic">x</mi></mrow><annotation encoding="application/x-tex">\boldsymbol{x}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.44444em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord boldsymbol">x</span></span></span></span></span></span>中，所有权重放到向量<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold-italic">w</mi></mrow><annotation encoding="application/x-tex">\boldsymbol{w}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.44444em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord boldsymbol" style="margin-right:.02778em">w</span></span></span></span></span></span>中，那么可以用点积来简洁表达模型：</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mover accent="true"><mi>y</mi><mo stretchy="true">^</mo></mover><mo>=</mo><mi><mrow><msup><mi mathvariant="bold-italic">w</mi><mi mathvariant="bold-italic">T</mi></msup><mi mathvariant="bold-italic">x</mi></mrow></mi><mo>+</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">\widehat{y} = \boldsymbol{w^Tx} +b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.865em;vertical-align:-.19444em"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.67056em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">y</span></span></span><span class="svg-align" style="width:calc(100% - .11112em);margin-left:.11112em;top:-3.43056em"><span class="pstrut" style="height:3em"></span><span style="height:.24em"><svg width="100%" height="0.24em" viewBox="0 0 1062 239" preserveAspectRatio="none"><path d="M529 0h5l519 115c5 1 9 5 9 10 0 1-1 2-1 3l-4 22
c-1 5-5 9-11 9h-2L532 67 19 159h-2c-5 0-9-4-11-9l-5-22c-1-6 2-12 8-13z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.19444em"><span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.9766069999999999em;vertical-align:-.08333em"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord boldsymbol" style="margin-right:.02778em">w</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8932769999999999em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord boldsymbol mtight" style="margin-right:.15972em">T</span></span></span></span></span></span></span></span><span class="mord boldsymbol">x</span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord mathnormal">b</span></span></span></span></span></p><p>线性回归的目标是找到一组权重向量和偏置，当给定从X的同分布中取样的新样本特征时，这组权重向量和偏置能够使得新样本预测标签的误差尽可能小。</p><p>在开始寻找模型参数之前，还需要：</p><ol><li>评价模型质量的方法，也就是如何评价这组参数是好是坏；</li><li>一种能够更新模型以提高模型预测质量的方法；</li></ol><h2 id="损失函数"><a class="markdownIt-Anchor" href="#损失函数"></a> 损失函数</h2><p>损失函数能够量化目标的实际值与预测值之间的差距，通常会选择非负数作为损失，且数值越小表示损失越小，完美预测时损失为0。回归问题中最常用的损失函数是平方误差函数，当样本i的预测值为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mover accent="true"><mi>y</mi><mo stretchy="true">^</mo></mover><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msup></mrow><annotation encoding="application/x-tex">\widehat{y}^{ (i) }</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0824399999999998em;vertical-align:-.19444em"></span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.67056em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">y</span></span></span><span class="svg-align" style="width:calc(100% - .11112em);margin-left:.11112em;top:-3.43056em"><span class="pstrut" style="height:3em"></span><span style="height:.24em"><svg width="100%" height="0.24em" viewBox="0 0 1062 239" preserveAspectRatio="none"><path d="M529 0h5l519 115c5 1 9 5 9 10 0 1-1 2-1 3l-4 22
c-1 5-5 9-11 9h-2L532 67 19 159h-2c-5 0-9-4-11-9l-5-22c-1-6 2-12 8-13z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.19444em"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8879999999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span>，对应真实标签为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>y</mi><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msup></mrow><annotation encoding="application/x-tex">y^{(i)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0824399999999998em;vertical-align:-.19444em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8879999999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span>时，平方误差可以定义为：</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msup><mi>l</mi><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">(</mo><mi>w</mi><mo separator="true">,</mo><mi>b</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mo stretchy="false">(</mo><msup><mover accent="true"><mi>y</mi><mo stretchy="true">^</mo></mover><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msup><mo>−</mo><msup><mi>y</mi><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msup><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">l^{(i)}(w,b) = \frac{1}{2} (\widehat{y}^{(i) } - y^{(i)} )^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.188em;vertical-align:-.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.01968em">l</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.938em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:.02691em">w</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathnormal">b</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:2.00744em;vertical-align:-.686em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mopen">(</span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.67056em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">y</span></span></span><span class="svg-align" style="width:calc(100% - .11112em);margin-left:.11112em;top:-3.43056em"><span class="pstrut" style="height:3em"></span><span style="height:.24em"><svg width="100%" height="0.24em" viewBox="0 0 1062 239" preserveAspectRatio="none"><path d="M529 0h5l519 115c5 1 9 5 9 10 0 1-1 2-1 3l-4 22
c-1 5-5 9-11 9h-2L532 67 19 159h-2c-5 0-9-4-11-9l-5-22c-1-6 2-12 8-13z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.19444em"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.938em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1.188em;vertical-align:-.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.938em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8641079999999999em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span></p><p>常数<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mn>2</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.190108em;vertical-align:-.345em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.845108em"><span style="top:-2.6550000000000002em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>不会带来本质差别，只是方便求导后约去，形式简单一些。</p><p>这是单个样本的损失计算。</p><p>为了度量模型在整个数据集上的质量，需要计算在n个样本上的损失均值，等价于求和。</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>L</mi><mo stretchy="false">(</mo><mi>w</mi><mo separator="true">,</mo><mi>b</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><msup><mi>l</mi><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">(</mo><mi>w</mi><mo separator="true">,</mo><mi>b</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mfrac><mn>1</mn><mn>2</mn></mfrac><mo stretchy="false">(</mo><mi><mrow><msup><mi mathvariant="bold-italic">w</mi><mi mathvariant="bold-italic">T</mi></msup><msup><mi mathvariant="bold-italic">x</mi><mrow><mo stretchy="false">(</mo><mi mathvariant="bold-italic">i</mi><mo stretchy="false">)</mo></mrow></msup></mrow></mi><mo>+</mo><mi>b</mi><mo>−</mo><msup><mi>y</mi><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msup><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">L(w, b) = \frac{1}{n} l^{ (i) } (w, b) = \frac{1}{n} \sum^{n}_{i=1} \frac{1}{2} (\boldsymbol{w^Tx^{ (i) } } + b - y^{(i)} )^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal">L</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:.02691em">w</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathnormal">b</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:2.00744em;vertical-align:-.686em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">n</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:.01968em">l</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.938em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:.02691em">w</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathnormal">b</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:2.929066em;vertical-align:-1.277669em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">n</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000002em"><span style="top:-1.872331em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em"><span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mopen">(</span><span class="mord"><span class="mord"><span class="mord"><span class="mord boldsymbol" style="margin-right:.02778em">w</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8932769999999999em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord boldsymbol mtight" style="margin-right:.15972em">T</span></span></span></span></span></span></span></span><span class="mord"><span class="mord boldsymbol">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.938em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mathbf mtight">(</span><span class="mord boldsymbol mtight">i</span><span class="mclose mathbf mtight">)</span></span></span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.77777em;vertical-align:-.08333em"></span><span class="mord mathnormal">b</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1.188em;vertical-align:-.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.938em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8641079999999999em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span></p><p>在训练模型时，希望寻找一组参数$ (\boldsymbol{w^{\ast} }, b^{\ast} )$，这组参数能最小化在所有训练样本上的总损失，即：</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi><msup><mi mathvariant="bold-italic">w</mi><mo mathvariant="bold-italic">∗</mo></msup></mi><mo separator="true">,</mo><msup><mi>b</mi><mo>∗</mo></msup><mo>=</mo><mi><munder><mo><mi>arg</mi><mo>⁡</mo><mi>min</mi><mo>⁡</mo></mo><mrow><mi mathvariant="bold-italic">w</mi><mo separator="true">,</mo><mi>b</mi></mrow></munder></mi><mi>L</mi><mo stretchy="false">(</mo><mi mathvariant="bold-italic">w</mi><mo separator="true">,</mo><mi>b</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\boldsymbol{w^*}, b^* =\underset{\boldsymbol{w} , b } { \arg\min } L( \boldsymbol{w}, b )</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.937994em;vertical-align:-.19444em"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord boldsymbol" style="margin-right:.02778em">w</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.7435539999999999em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mathbf mtight">∗</span></span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.738696em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.8326559999999998em;vertical-align:-1.0826559999999998em"></span><span class="mord"><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.6678600000000001em"><span style="top:-2.153452em;margin-left:0"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord boldsymbol mtight" style="margin-right:.02778em">w</span></span></span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">b</span></span></span></span><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span><span class="mop"><span class="mop">ar<span style="margin-right:.01389em">g</span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mop">min</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.0826559999999998em"><span></span></span></span></span></span></span><span class="mord mathnormal">L</span><span class="mopen">(</span><span class="mord"><span class="mord"><span class="mord boldsymbol" style="margin-right:.02778em">w</span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathnormal">b</span><span class="mclose">)</span></span></span></span></span></p><h2 id="随机梯度下降"><a class="markdownIt-Anchor" href="#随机梯度下降"></a> 随机梯度下降</h2><p>梯度下降(Gradient Descent)通过不断在损失函数递减的方向上更新参数来降低误差。</p><p>梯度下降最简单的用法是计算损失函数关于模型参数的导数(也可以称为梯度)，但在实际的执行中速度会非常慢，因为在每次更新参数前，都必须遍历数据集。因此，在实际中，会在每次更新的时候，随机抽取一小批样本，这种变体称为小批量随机梯度下降。</p><p>在每次迭代中，首先随机抽样一个小批量<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">B</mi></mrow><annotation encoding="application/x-tex">\mathcal{B}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord"><span class="mord mathcal" style="margin-right:.03041em">B</span></span></span></span></span>，它是由固定数量的训练样本组成的，然后计算小批量的平均损失关于模型参数的导数，最后将导数值乘上学习率<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>η</mi></mrow><annotation encoding="application/x-tex">\eta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathnormal" style="margin-right:.03588em">η</span></span></span></span>，并从当前参数中减掉。</p><p>用数学公式表示(<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">∂</mi></mrow><annotation encoding="application/x-tex">\partial</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord" style="margin-right:.05556em">∂</span></span></span></span>表示偏导数)：</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mo stretchy="false">(</mo><mi mathvariant="bold-italic">w</mi><mo separator="true">,</mo><mi>b</mi><mo stretchy="false">)</mo><mo>←</mo><mo stretchy="false">(</mo><mi mathvariant="bold-italic">w</mi><mo separator="true">,</mo><mi>b</mi><mo stretchy="false">)</mo><mo>−</mo><mfrac><mi>η</mi><mrow><mi mathvariant="normal">∣</mi><mi mathvariant="script">B</mi><mi mathvariant="normal">∣</mi></mrow></mfrac><munder><mo>∑</mo><mrow><mi>i</mi><mo>∈</mo><mi mathvariant="script">B</mi></mrow></munder><msub><mi mathvariant="normal">∂</mi><mrow><mo stretchy="false">(</mo><mi mathvariant="bold-italic">w</mi><mo separator="true">,</mo><mi>b</mi><mo stretchy="false">)</mo></mrow></msub><msup><mi>l</mi><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">(</mo><mi mathvariant="bold-italic">w</mi><mo separator="true">,</mo><mi>b</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(\boldsymbol{w}, b) \leftarrow (\boldsymbol{w}, b) - \frac{\eta}{| \mathcal{B} |} \sum_{i \in \mathcal{B} } \partial_{ (\boldsymbol{w}, b) } l^{ (i) } (\boldsymbol{w}, b)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord"><span class="mord"><span class="mord boldsymbol" style="margin-right:.02778em">w</span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathnormal">b</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">←</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord"><span class="mord"><span class="mord boldsymbol" style="margin-right:.02778em">w</span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathnormal">b</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:2.429266em;vertical-align:-1.321706em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1075599999999999em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">∣</span><span class="mord"><span class="mord mathcal" style="margin-right:.03041em">B</span></span><span class="mord">∣</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">η</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.936em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.050005em"><span style="top:-1.8556639999999998em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">∈</span><span class="mord mtight"><span class="mord mathcal mtight" style="margin-right:.03041em">B</span></span></span></span></span><span style="top:-3.0500049999999996em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.321706em"><span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord" style="margin-right:.05556em">∂</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.34480000000000005em"><span style="top:-2.5198em;margin-left:-.05556em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mtight"><span class="mord boldsymbol mtight" style="margin-right:.02778em">w</span></span></span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">b</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.3551999999999999em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:.01968em">l</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.938em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord"><span class="mord boldsymbol" style="margin-right:.02778em">w</span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathnormal">b</span><span class="mclose">)</span></span></span></span></span></p><p>总结一下，算法步骤为：</p><ol><li>初始化模型参数值，如随机初始化</li><li>从数据集中随机抽取小批量样本并在负梯度方向上更新参数，并不断迭代这一步骤</li></ol><p>批量大小batch-size和学习率<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>η</mi></mrow><annotation encoding="application/x-tex">\eta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathnormal" style="margin-right:.03588em">η</span></span></span></span>称为超参数，不在训练过程中更新，而是手动预先指定，根据训练迭代结果来调整。</p><h2 id="线性回归从零实现"><a class="markdownIt-Anchor" href="#线性回归从零实现"></a> 线性回归从零实现</h2><p>首先导入所需要的包，其中将matplotlib设置为嵌入显示。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">%matplotlib inline<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> matplotlib <span class="hljs-keyword">import</span> pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> random<br></code></pre></td></tr></table></figure><h3 id="生成数据集"><a class="markdownIt-Anchor" href="#生成数据集"></a> 生成数据集</h3><p>构造一个简单的人工训练数据集，可以使我们直观比较学到的参数和真实的模型参数的区别。</p><p>设训练数据集样本数为1000，特征数为2。给定随机生成的批量样本特征<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">X</mi></mrow><annotation encoding="application/x-tex">\bf X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68611em;vertical-align:0"></span><span class="mord"><span class="mord mathbf">X</span></span></span></span></span>，使用线性回归模型真实权重<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold-italic">w</mi><mo>=</mo><mo stretchy="false">[</mo><mn>2</mn><mo separator="true">,</mo><mo>−</mo><mn>3.4</mn><msup><mo stretchy="false">]</mo><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">\boldsymbol{w} = [2, -3.4]^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.44444em;vertical-align:0"></span><span class="mord"><span class="mord"><span class="mord boldsymbol" style="margin-right:.02778em">w</span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.0913309999999998em;vertical-align:-.25em"></span><span class="mopen">[</span><span class="mord">2</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord">−</span><span class="mord">3</span><span class="mord">.</span><span class="mord">4</span><span class="mclose"><span class="mclose">]</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8413309999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.13889em">T</span></span></span></span></span></span></span></span></span></span></span>和偏差<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi><mo>=</mo><mn>4.2</mn></mrow><annotation encoding="application/x-tex">b = 4.2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord mathnormal">b</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">4</span><span class="mord">.</span><span class="mord">2</span></span></span></span>，以及一个随机噪声项来生成标签。</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="bold-italic">y</mi><mo>=</mo><mi mathvariant="bold">X</mi><mi mathvariant="bold-italic">w</mi><mo>+</mo><mi>b</mi><mo>+</mo><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">\boldsymbol{y} = \mathbf{X}\boldsymbol{w} +b + \epsilon</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.63888em;vertical-align:-.19444em"></span><span class="mord"><span class="mord"><span class="mord boldsymbol" style="margin-right:.03704em">y</span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.76944em;vertical-align:-.08333em"></span><span class="mord"><span class="mord mathbf">X</span></span><span class="mord"><span class="mord"><span class="mord boldsymbol" style="margin-right:.02778em">w</span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.77777em;vertical-align:-.08333em"></span><span class="mord mathnormal">b</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathnormal">ϵ</span></span></span></span></span></p><p>其中噪声项<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">\epsilon</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathnormal">ϵ</span></span></span></span>服从均值为0，标准差为0.01的正态分布，代表了数据集中无意义的干扰。</p><p>生成数据集代码为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">num_inputs = <span class="hljs-number">2</span><br>num_examples = <span class="hljs-number">1000</span><br>true_w = [<span class="hljs-number">2</span>, -<span class="hljs-number">3</span>,<span class="hljs-number">4</span>]<br>true_b = <span class="hljs-number">4.2</span><br><br><span class="hljs-comment"># 生成数据样本，维度(1000, 2)</span><br>features = torch.randn(num_examples, num_inputs, dtype=torch.float32)<br><span class="hljs-comment"># 使用真实w和b构造标签</span><br>labels = true_w[<span class="hljs-number">0</span>] * features[:, <span class="hljs-number">0</span>] + true_w[<span class="hljs-number">1</span>] * features[:, <span class="hljs-number">1</span>] + true_b<br><span class="hljs-comment"># 添加噪声项</span><br>labels += torch.tensor(np.random.normal(<span class="hljs-number">0</span>, <span class="hljs-number">0.01</span>, size=labels.size()), dtype=torch.float32)<br></code></pre></td></tr></table></figure><p>其中，<code>features</code>每一行是一个长度为2的向量，<code>labels</code>的每一行是一个长度为1的向量(标量)。</p><p>通过第二个特征<code>features[:, 1]</code>和标签<code>labels</code>的散点图，可以更直观观察两者间线性关系。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> matplotlib_inline.backend_inline<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">use_svg_display</span>(): <br>    matplotlib_inline.backend_inline.set_matplotlib_formats(<span class="hljs-string">&#x27;svg&#x27;</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">set_figsize</span>(<span class="hljs-params">figsize=(<span class="hljs-params"><span class="hljs-number">9</span>, <span class="hljs-number">6</span></span>)</span>): <br>    use_svg_display()<br>    plt.rcParams[<span class="hljs-string">&#x27;figure.figsize&#x27;</span>] = figsize<br><br>set_figsize()<br><span class="hljs-comment"># 散点图，前两个参数是x和y，数组类型(n,)；s-&gt;散点的面积大小，默认20; aplha-&gt; 散点透明度,0完全透明，1不透明</span><br>plt.scatter(features[:, <span class="hljs-number">1</span>].numpy(), labels.numpy(), <span class="hljs-number">10</span>, alpha=<span class="hljs-number">0.9</span>)<br></code></pre></td></tr></table></figure><p>生成图像为：</p><img src="https://crayon-1302863897.cos.ap-beijing.myqcloud.com/image/散点图.svg" srcset="/img/loading.gif" lazyload alt="散点图" style="zoom:70%"><h3 id="读取数据"><a class="markdownIt-Anchor" href="#读取数据"></a> 读取数据</h3><p>在训练模型时，需要遍历数据集并不断读取小批量数据样本，因此定义一个函数：每次返回<code>batch-size</code>个随机样本的特征和标签。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">data_iter</span>(<span class="hljs-params">batch_size, features, labels</span>): <br>    <span class="hljs-comment"># 获得样本总数</span><br>    num_examples = <span class="hljs-built_in">len</span>(features)<br>    <span class="hljs-comment"># 索引列表</span><br>    indices = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(num_examples))<br>    <span class="hljs-comment"># 将索引打乱，是inplace的，也就是在原列表上打乱</span><br>    random.shuffle(indices)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, num_examples, batch_size): <br>        <span class="hljs-comment">#最后一次可能不够一个batch，因此进行最小值比较</span><br>        j = torch.LongTensor(indices[i: <span class="hljs-built_in">min</span>(i + batch_size, num_examples) ]) <br>        <span class="hljs-comment"># 使用yield返回迭代器，会保存函数执行进度，</span><br>        <span class="hljs-comment"># 下次再调用会定位到上次yield位置开始执行</span><br>        <span class="hljs-comment"># 使用index_select方法，0表示按行索引，j是要选取的索引列表</span><br>        <span class="hljs-keyword">yield</span> features.index_select(<span class="hljs-number">0</span>, j), labels.index_select(<span class="hljs-number">0</span>, j)<br></code></pre></td></tr></table></figure><p>可以测试一下， 设定<code>batch_size = 10</code>，读取第一个小批量数据样本。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">batch_size = <span class="hljs-number">10</span><br><span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> data_iter(batch_size, features, labels): <br>    <span class="hljs-built_in">print</span>(X, y)<br>    <span class="hljs-keyword">break</span><br></code></pre></td></tr></table></figure><h3 id="初始化模型参数"><a class="markdownIt-Anchor" href="#初始化模型参数"></a> 初始化模型参数</h3><p>将权重初始化为均值为0，标准差为0.01的正态随机数，偏差初始化为0。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">w = torch.tensor(np.random.normal(<span class="hljs-number">0</span>, <span class="hljs-number">0.01</span>, (num_inputs, <span class="hljs-number">1</span>)), dtype=torch.float32)<br>b = torch.zeros(<span class="hljs-number">1</span>, dtype=torch.float32)<br><br></code></pre></td></tr></table></figure><p>之后的模型训练中，需要对这些参数求梯度来迭代参数的值，因此要让参数的<code>requires_grad=True</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">w.requires_grad_(requires_grad=<span class="hljs-literal">True</span>)<br>b.requires_grad_(requires_grad=<span class="hljs-literal">True</span>) <br><br></code></pre></td></tr></table></figure><h3 id="定义模型"><a class="markdownIt-Anchor" href="#定义模型"></a> 定义模型</h3><p>需要将输入特征<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">X</mi></mrow><annotation encoding="application/x-tex">\mathbf X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68611em;vertical-align:0"></span><span class="mord mathbf">X</span></span></span></span>和权重矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">w</mi></mrow><annotation encoding="application/x-tex">\bf w</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.44444em;vertical-align:0"></span><span class="mord"><span class="mord mathbf" style="margin-right:.01597em">w</span></span></span></span></span>向量乘法后加上偏置<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord mathnormal">b</span></span></span></span>，偏置<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord mathnormal">b</span></span></span></span>是一个标量，python有广播机制，当用向量加标量时，标量会被加到向量的每个分量上。</p><p>使用<code>torch.mm</code>函数进行矩阵相乘。</p><blockquote><p><code>torch.mm</code>函数用于矩阵乘法，但只适用于二维矩阵相乘，如果传入高维矩阵，则会报错。</p><p>如果x维度(n,m)，y维度(m,p)，<a target="_blank" rel="noopener" href="http://xn--torch-8k6h.mm">则torch.mm</a>(x,y)返回一个(n,p)维矩阵。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">linreg</span>(<span class="hljs-params">X, w, b</span>): <br>    <span class="hljs-keyword">return</span> torch.mm(X, w) + b<br></code></pre></td></tr></table></figure><h3 id="定义损失函数"><a class="markdownIt-Anchor" href="#定义损失函数"></a> 定义损失函数</h3><p>使用上面描述的平方损失来定义线性回归的损失函数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># y_hat是预测值，y是真实值</span><br><span class="hljs-comment"># 使用view函数确保y和y_hat维度相同，注意在pytorch的MSELoss中没有除2</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">squared_loss</span>(<span class="hljs-params">y_hat, y</span>): <br>    <span class="hljs-keyword">return</span> (y_hat - y.view(y_hat.size()))**<span class="hljs-number">2</span> / <span class="hljs-number">2</span> <br></code></pre></td></tr></table></figure><h3 id="定义优化函数"><a class="markdownIt-Anchor" href="#定义优化函数"></a> 定义优化函数</h3><p>实现上面介绍的小批量随机梯度下降算法，这里的自动求梯度模块计算得到的梯度是一个批量样本的梯度和，除以批量大小来得到平均值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">sgd</span>(<span class="hljs-params">params, lr, batch_size</span>): <br>    <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> params: <br>        <span class="hljs-comment"># 使用data属性来改变参数值</span><br>        param.data -= lr * param.grad / batch_size<br></code></pre></td></tr></table></figure><h3 id="训练模型"><a class="markdownIt-Anchor" href="#训练模型"></a> 训练模型</h3><p>在训练中，将不断迭代模型参数。在每次迭代中，根据当前读取的小批量数据样本，通过调用反向传播函数<code>backward</code>计算小批量随机梯度，并调用优化算法<code>sgd</code>迭代模型参数。</p><p>由于之前设批量大小<code>batch_size</code>为10，每个小批量损失<code>l</code>的维度为<code>(10, 1)</code>。由于变量<code>l</code>不是一个标量，因此可以调用<code>sum()</code>函数求和得到一个标量，再运行<code>backward()</code>得到该变量有关模型参数的梯度。</p><p>注意更新完参数后，需要将参数梯度清零。</p><p>在一个迭代周期(epoch)中，将完整执行一遍<code>data_iter</code>函数。这里迭代周期<code>num_epochs</code>和学习率<code>lr</code>都是超参数，分别设为3和0.03。在实践中，大多数参数需要反复尝试来调节。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python">lr = <span class="hljs-number">0.03</span><br>num_epochs = <span class="hljs-number">3</span><br>net = linreg<br>loss = squared_loss<br><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs): <br>    <span class="hljs-comment"># 每次迭代中，都会遍历数据集样本</span><br>    <span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> data_iter(batch_size, features, labels): <br>        l = loss(net(X, w, b), y).<span class="hljs-built_in">sum</span>()<br>        <span class="hljs-comment"># 反向传播，计算每个参数的梯度</span><br>        l.backward()<br>        <span class="hljs-comment"># 优化，更新参数    </span><br>        sgd([w,b], lr, batch_size)<br>        <span class="hljs-comment"># 梯度清零</span><br>        w.grad.data.zero_()<br>        b.grad.data.zero_()<br>    <br>    <span class="hljs-comment"># 每次迭代完成后，计算每个样本的损失值</span><br>    train_l = loss(net(features, w, b), labels)<br>    <span class="hljs-comment"># 打印迭代次数和平均损失值</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;epoch %d, loss %f&#x27;</span> % (epoch + <span class="hljs-number">1</span>, train_l.mean().item()))<br></code></pre></td></tr></table></figure><p>输出为：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs plain">epoch 1, loss 0.032384<br>epoch 2, loss 0.000117<br>epoch 3, loss 0.000051<br></code></pre></td></tr></table></figure><p>可以查看训练完成后，设定参数和训练参数是否接近。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(true_w, <span class="hljs-string">&#x27;\n&#x27;</span>, w)<br><span class="hljs-built_in">print</span>(true_b, <span class="hljs-string">&#x27;\n&#x27;</span>, b)<br><span class="hljs-comment"># 输出</span><br><span class="hljs-comment"># [2, -3.4] </span><br><span class="hljs-comment"># tensor([[ 1.9996],[-3.3998]], requires_grad=True)</span><br><span class="hljs-comment"># 4.2 </span><br><span class="hljs-comment"># tensor([4.1993], requires_grad=True)</span><br></code></pre></td></tr></table></figure><p>可以看到，训练后的模型参数十分接近真实的参数。</p><h2 id="线性回归简洁实现"><a class="markdownIt-Anchor" href="#线性回归简洁实现"></a> 线性回归简洁实现</h2><p>在这节中，使用PyTorch框架更简洁地实现线性回归。</p><h3 id="生成数据集-2"><a class="markdownIt-Anchor" href="#生成数据集-2"></a> 生成数据集</h3><p>与上一节中的数据集相同，<code>features</code>是训练数据特征，<code>labels</code>是标签。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">num_inputs = <span class="hljs-number">2</span><br>num_examples = <span class="hljs-number">1000</span><br><br>true_w = [<span class="hljs-number">2</span>, -<span class="hljs-number">3.4</span>]<br>true_b = <span class="hljs-number">4.2</span><br><br>features = torch.tensor(np.random.normal(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, (num_examples, num_inputs)), dtype=torch.<span class="hljs-built_in">float</span>)<br>labels = true_w[<span class="hljs-number">0</span>] * features[:, <span class="hljs-number">0</span>] + true_w[<span class="hljs-number">1</span>] * features[:, <span class="hljs-number">1</span>] + true_b<br>labels += torch.tensor(np.random.normal(<span class="hljs-number">0</span>, <span class="hljs-number">0.01</span>, size=labels.size()), dtype=torch.<span class="hljs-built_in">float</span>) <br></code></pre></td></tr></table></figure><h3 id="读取数据-2"><a class="markdownIt-Anchor" href="#读取数据-2"></a> 读取数据</h3><p>PyTorch提供了<code>data</code>包来读取数据，由于<code>data</code>常用作变量名，因此将导入的<code>data</code>用<code>Data</code>代替，和上节一样，将随机读取包含10个数据样本的小批量。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch.utils.data <span class="hljs-keyword">as</span> Data<br><br>batch_size = <span class="hljs-number">10</span><br><span class="hljs-comment"># 将训练数据的特征和标签组合</span><br>dataset = Data.TensorDataset(features, labels)<br><span class="hljs-comment"># 随机读取小批量</span><br>data_iter = Data.DataLoader(dataset, batch_size, shuffle=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure><p>这里的<code>data_iter</code>和上一节用法一样，<code>DataLoader</code>包含数据集和取样器，用来分小批量地迭代数据样本。</p><h3 id="定义模型-2"><a class="markdownIt-Anchor" href="#定义模型-2"></a> 定义模型</h3><p>PyTorch提供了大量预定义的层。</p><p>首先，导入<code>torch.nn</code>模块，<code>nn</code>是<code>neural network</code>的缩写，该模块定义了大量神经网络的层。<code>nn</code>的核心数据结构是<code>Module</code>，它是一个抽象概念，既可以表示神经网络中的某个层，也可以表示一个包含很多层的神经网络。</p><p>在实际使用中，最常见的做法是继承<code>nn.Module</code>，撰写自己的网络层，一个<code>nn.Module</code>实例应该包含一些层以及返回输出的前向传播(forward)方法。</p><p><code>Linear</code>类中需要两个参数，第一个指定输入特征数量，即2，第二个指定输出特征数量，一个标量，为1。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">LinearNet</span>(nn.Module): <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, n_feature</span>):<br>        <span class="hljs-built_in">super</span>(LinearNet, self).__init__()<br>        <span class="hljs-comment"># 线性回归层</span><br>        self.linear = nn.Linear(n_feature, <span class="hljs-number">1</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>): <br>        y = self.linear(x)<br>        <span class="hljs-keyword">return</span> y<br><br>net = LinearNet(num_inputs)<br><span class="hljs-built_in">print</span>(net)<br></code></pre></td></tr></table></figure><p><code>print(net)</code>可以输出网络结构。</p><p>还可以使用<code>nn.Sequential</code>来更方便的搭建网络，<code>Sequential</code>是一个有序的容器，网络层将按照传入<code>Sequential</code>的顺序依次添加到计算图中。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 写法一</span><br>net = nn.Sequential(<br>    nn.Linear(num_inputs, <span class="hljs-number">1</span>)<br>)<br><span class="hljs-comment"># 写法二, linear是该层的名字</span><br>net = nn.Sequential()<br>net.add_module(<span class="hljs-string">&#x27;linear&#x27;</span>, nn.Linear(num_inputs, <span class="hljs-number">1</span>))<br><span class="hljs-comment"># 写法三</span><br><span class="hljs-keyword">from</span> collections <span class="hljs-keyword">import</span> OrderedDict<br>net = nn.Sequential(OrderedDict([<br>          (<span class="hljs-string">&#x27;linear&#x27;</span>, nn.Linear(num_inputs, <span class="hljs-number">1</span>))<br>        ]))<br></code></pre></td></tr></table></figure><p><code>OrderedDict</code>是一个有序的字典，可以自定义层名字和结构。</p><p>可以通过<code>net.parameters()</code>来查看模型所有的可学习参数，该函数会返回一个生成器。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> net.parameters(): <br>    <span class="hljs-built_in">print</span>(param)<br>    <br><span class="hljs-comment"># 输出</span><br><span class="hljs-comment"># Parameter containing:</span><br><span class="hljs-comment"># tensor([[ 0.1954, -0.2418]], requires_grad=True)</span><br><span class="hljs-comment"># Parameter containing:</span><br><span class="hljs-comment"># tensor([-0.5784], requires_grad=True)</span><br></code></pre></td></tr></table></figure><blockquote><p>注意：<code>torch.nn</code>仅支持输入一个batch样本，不支持单个样本输入，如果只有单个样本，可以使用<code>input.unsqueeze(0)</code>来添加一维。</p></blockquote><p>在使用<code>net</code>之前，需要初始化模型参数。PyTorch在<code>init</code>模块中提供了多种参数初始化方法，这里使用<code>init.normal_</code>将权重参数每个元素初始化为随机采样于均值为0， 标准差为0.01的正态分布，偏差初始化为0。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> init<br>init.normal_(net.linear.weight, mean=<span class="hljs-number">0</span>, std=<span class="hljs-number">0.01</span>)<br>init.constant_(net.linear.bias, val=<span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure><p>这里也可以直接修改<code>data</code>属性，</p><p>即<code>net.linear.weight.data.normal_(0, 0.01); net.linear.bias.data.fill_(0)</code>。</p><p>如果是使用<code>Sequential</code>定义模型的，则使用<code>net[0].weight</code>和<code>net[0].bias</code>获取模型参数。</p><h3 id="定义损失函数-2"><a class="markdownIt-Anchor" href="#定义损失函数-2"></a> 定义损失函数</h3><p>PyTorch在<code>nn</code>模块中提供了各种损失函数，可以看做一种特殊的层，PyTorch也将这些损失函数实现为<code>nn.Module</code>的子类。现在使用PyTorch提供的均方误差损失作为模型的损失函数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">loss = nn.MSELoss()<br></code></pre></td></tr></table></figure><p>计算均方误差使用的是MSELoss类，也称为平方L2范数，默认情况下，返回所有样本损失的平均值。</p><h3 id="定义优化算法"><a class="markdownIt-Anchor" href="#定义优化算法"></a> 定义优化算法</h3><p>PyTorch的<code>torch.optim</code>模块提供了很多常用的优化算法如<code>SGD</code>、<code>Adam</code>和<code>RMSProp</code>等。下面创建一个用于优化<code>net</code>参数的优化器实例，并指定学习率为0.03的小批量随机梯度下降(SGD)为优化算法。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch.optim <span class="hljs-keyword">as</span> optim<br><br>optimizer = optim.SGD(net.parameters(), lr=<span class="hljs-number">0.03</span>)<br><span class="hljs-built_in">print</span>(optimizer)<br><br><span class="hljs-comment"># 输出</span><br><span class="hljs-comment"># SGD (</span><br><span class="hljs-comment"># Parameter Group 0</span><br><span class="hljs-comment">#     dampening: 0</span><br><span class="hljs-comment">#     lr: 0.03</span><br><span class="hljs-comment">#     momentum: 0</span><br><span class="hljs-comment">#     nesterov: False</span><br><span class="hljs-comment">#     weight_decay: 0</span><br><span class="hljs-comment"># )</span><br></code></pre></td></tr></table></figure><p>还可以为不同子网络设置不同的学习率，在<code>fine-tune</code>时经常用到。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">optimizer = optim.SGD([<br>	<span class="hljs-comment"># 如果对某个参数不指定学习率，就使用最外层默认学习率</span><br>	&#123;<span class="hljs-string">&#x27;params&#x27;</span>: net.subnet1.parameters()&#125;, <span class="hljs-comment"># 使用默认学习率0.03</span><br>	&#123;<span class="hljs-string">&#x27;params&#x27;</span>: net.subnet2.parameters(), <span class="hljs-string">&#x27;lr&#x27;</span>: <span class="hljs-number">0.01</span>&#125;<br>], lr = <span class="hljs-number">0.03</span>)<br></code></pre></td></tr></table></figure><p>有时候不想让学习率固定为常数，调整学习率有两种做法，一种是修改<code>optimizer.param_groups</code>中对应的学习率，另一种是更简单也更推荐的做法：新建优化器，因为<code>optimizer</code>十分轻量级，构建开销很小，因此可以构建新的optimizer，但是对于使用动量的优化器(如Adam)，会丢失动量等状态信息。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 调整学习率</span><br><span class="hljs-keyword">for</span> param_group <span class="hljs-keyword">in</span> optimizer.param_groups: <br>    param_group[<span class="hljs-string">&#x27;lr&#x27;</span>] *= <span class="hljs-number">0.1</span> <span class="hljs-comment"># 学习率为之前的0.1倍</span><br></code></pre></td></tr></table></figure><h3 id="训练"><a class="markdownIt-Anchor" href="#训练"></a> 训练</h3><p>回顾一下，在每个迭代中，将完整遍历一次数据集，不停获取一个小批量输入和相应标签，对于每一个小批量，将进行以下步骤：</p><ul><li>通过调用<code>net(X)</code>生成预测并计算损失<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi></mrow><annotation encoding="application/x-tex">l</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.01968em">l</span></span></span></span>(前向传播)</li><li>进行反向传播计算参数梯度</li><li>调用优化器更新模型参数</li></ul><p>为了更好衡量训练效果，计算每个迭代周期后的损失，并打印它来监控整个训练过程。</p><p>调用<code>optim</code>实例的<code>step</code>函数迭代更新模型参数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python">num_epochs = <span class="hljs-number">3</span><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, num_epochs + <span class="hljs-number">1</span>): <br>    <span class="hljs-keyword">for</span> X,y <span class="hljs-keyword">in</span> data_iter: <br>        output = net(X)<br>        <span class="hljs-comment"># 调用view,将标签看成n*1的向量</span><br>        l = loss(output, y.view(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>        <span class="hljs-comment"># 梯度清零，相等于net.zero_grad()</span><br>        optimizer.zero_grad()<br>        l.backward()<br>        optimizer.step()<br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;epoch %d, loss: %f&#x27;</span> % (epoch, l.item()))<br>    <br><span class="hljs-comment"># 输出</span><br><span class="hljs-comment"># epoch 1, loss: 0.000280</span><br><span class="hljs-comment"># epoch 2, loss: 0.000090</span><br><span class="hljs-comment"># epoch 3, loss: 0.000105</span><br></code></pre></td></tr></table></figure><p>将实际参数和训练参数进行比较。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">linear = net.linear<br><span class="hljs-built_in">print</span>(true_w, linear.weight)<br><span class="hljs-built_in">print</span>(true_b, linear.bias)<br><br><span class="hljs-comment"># 输出</span><br><span class="hljs-comment"># [2, -3.4] Parameter containing:</span><br><span class="hljs-comment"># tensor([[ 2.0006, -3.3992]], requires_grad=True)</span><br><span class="hljs-comment"># 4.2 Parameter containing:</span><br><span class="hljs-comment"># tensor([4.2004], requires_grad=True)</span><br></code></pre></td></tr></table></figure></div><hr><div><div class="post-metas my-3"><div class="post-meta mr-3 d-flex align-items-center"><i class="iconfont icon-category"></i> <span class="category-chains"><span class="category-chain"><a href="/categories/deeplearning/" class="category-chain-item">深度学习</a> <span>></span> <a href="/categories/deeplearning/dive-into-dp/" class="category-chain-item">动手学深度学习</a></span></span></div><div class="post-meta"><i class="iconfont icon-tags"></i> <a href="/tags/practice/">#深度学习实战</a></div></div><div class="license-box my-3"><div class="license-title"><div>1-线性回归</div><div>https://zhaoquaner.github.io/2022/11/21/DeepLearning/practice/1-线性回归/</div></div><div class="license-meta"><div class="license-meta-item license-meta-date"><div>更新于</div><div>2022年11月23日</div></div><div class="license-meta-item"><div>许可协议</div><div><a target="_blank" href="https://creativecommons.org/licenses/by/4.0/"><span class="hint--top hint--rounded" aria-label="BY - 署名"><i class="iconfont icon-by"></i></span></a></div></div></div><div class="license-icon iconfont"></div></div></div></article></div></div></div><div class="side-col d-none d-lg-block col-lg-2"></div></div></div><script>Fluid.utils.createScript("https://lib.baomitu.com/mermaid/8.13.10/mermaid.min.js",function(){mermaid.initialize({theme:"default"})})</script><a id="scroll-top-button" aria-label="TOP" href="#" role="button"><i class="iconfont icon-arrowup" aria-hidden="true"></i></a><div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable modal-lg" role="document"><div class="modal-content"><div class="modal-header text-center"><h4 class="modal-title w-100 font-weight-bold">搜索</h4><button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body mx-3"><div class="md-form mb-5"><input type="text" id="local-search-input" class="form-control validate"> <label data-error="x" data-success="v" for="local-search-input">关键词</label></div><div class="list-group" id="local-search-result"></div></div></div></div></div><div class="col-lg-7 mx-auto nopadding-x-md"><div class="container custom mx-auto"><link rel="stylesheet" href="https://crayon-1302863897.cos.ap-beijing.myqcloud.com/blog/css/APlayer.min.css"><div id="aplayer" style="display:none"></div><script src="https://crayon-1302863897.cos.ap-beijing.myqcloud.com/blog/blog_js/APlayer.min.js"></script></div></div></main><footer><div class="footer-inner"><div class="footer-content"><i class="iconfont icon-copyright"></i> <span>ZhaoXin, Built with </span><a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <span>& </span><a href="https://hexo.fluid-dev.com/" target="_blank" rel="nofollow noopener"><span>Fluid</span></a></div><div class="statistics"><span id="leancloud-site-pv-container" style="display:none">总访问量 <span id="leancloud-site-pv"></span> 次 </span><span id="leancloud-site-uv-container" style="display:none">总访客数 <span id="leancloud-site-uv"></span> 人</span></div></div></footer><script src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js"></script><link rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css"><script>NProgress.configure({showSpinner:!1,trickleSpeed:100}),NProgress.start(),window.addEventListener("load",function(){NProgress.done()})</script><script src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js"></script><script src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js"></script><script src="/js/events.js"></script><script src="/js/plugins.js"></script><script src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js"></script><script>!function(t){var e=Fluid.plugins.typing,i=t.getElementById("subtitle");i&&e&&e(i.getAttribute("data-typed-text"))}((window,document))</script><script src="/js/img-lazyload.js"></script><script>Fluid.utils.createScript("https://lib.baomitu.com/tocbot/4.18.0/tocbot.min.js",function(){var t,o=jQuery("#toc");0!==o.length&&window.tocbot&&(t=jQuery("#board-ctn").offset().top,window.tocbot.init({tocSelector:"#toc-body",contentSelector:".markdown-body",headingSelector:CONFIG.toc.headingSelector||"h1,h2,h3,h4,h5,h6",linkClass:"tocbot-link",activeLinkClass:"tocbot-active-link",listClass:"tocbot-list",isCollapsedClass:"tocbot-is-collapsed",collapsibleClass:"tocbot-is-collapsible",collapseDepth:CONFIG.toc.collapseDepth||0,scrollSmooth:!0,headingsOffset:-t}),0<o.find(".toc-list-item").length&&o.css("visibility","visible"))})</script><script>!function(){var i,t=CONFIG.code_language.enable&&CONFIG.code_language.default,c=CONFIG.copy_btn;(t||c)&&(i="",i+='<div class="code-widget">',i+="LANG",i+="</div>",jQuery(".markdown-body pre").each(function(){var e,a,n=jQuery(this);0<n.find("code.mermaid").length||0<n.find("span.line").length||(e="",t&&(e=CONFIG.code_language.default,0<n[0].children.length&&2<=n[0].children[0].classList.length&&n.children().hasClass("hljs")?e=n[0].children[0].classList[1]:n[0].getAttribute("data-language")?e=n[0].getAttribute("data-language"):n.parent().hasClass("sourceCode")&&0<n[0].children.length&&2<=n[0].children[0].classList.length?(e=n[0].children[0].classList[1],n.parent().addClass("code-wrapper")):n.parent().hasClass("markdown-body")&&0===n[0].classList.length&&n.wrap('<div class="code-wrapper"></div>'),e=e.toUpperCase().replace("NONE",CONFIG.code_language.default)),n.append(i.replace("LANG",e).replace('code-widget">',(a=n[0],(0<=Fluid.utils.getBackgroundLightness(a)?"code-widget-light":"code-widget-dark")+(c?' code-widget copy-btn" data-clipboard-snippet><i class="iconfont icon-copy"></i>':' code-widget">')))),c&&Fluid.utils.createScript("https://lib.baomitu.com/clipboard.js/2.0.10/clipboard.min.js",function(){new window.ClipboardJS(".copy-btn",{target:function(e){for(var a=e.parentNode.childNodes,n=0;n<a.length;n++)if("CODE"===a[n].tagName)return a[n]}}).on("success",function(e){e.clearSelection(),e.trigger.innerHTML=e.trigger.innerHTML.replace("icon-copy","icon-success"),setTimeout(function(){e.trigger.innerHTML=e.trigger.innerHTML.replace("icon-success","icon-copy")},2e3)})}))}))}()</script><script>Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));
  });</script><script>Fluid.utils.createScript("https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js",function(){Fluid.plugins.fancyBox()})</script><script>Fluid.plugins.imageCaption()</script><script src="/js/local-search.js"></script><script defer src="/js/leancloud.js"></script><script src="https://crayon-1302863897.cos.ap-beijing.myqcloud.com/blog/blog_js/music.js"></script><script src="https://crayon-1302863897.cos.ap-beijing.myqcloud.com/blog/blog_js/collapse.js"></script><script src="/js/boot.js"></script><noscript><div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div></noscript></body></html>